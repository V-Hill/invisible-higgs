{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search hyperparameter tuning\n",
    "In this notebook the grid search capability from the scikit-learn library is used to tune the hyperparameters of our Keras event level neural network.\n",
    "\n",
    "For further details see:\n",
    "    https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1) Using the Grid Search in scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Grid search method is a hyperparameter optimization technique.\n",
    "\n",
    "Scikit-learn provides an ready-made implementation of this via the GridSearchCV class.\n",
    "\n",
    "First a dictionary of hyperparameter to be tested is created. This gets passed to the GridSearchCV class constructor via the param_grid argument.\n",
    "\n",
    "The GridSearchCV process then constructs and evaluates one model for each combination of parameters. \n",
    "\n",
    "The average of several runs of the same model is used to provide cross validation of the models. By default, 3-fold cross validation is used. This can be changed by specifying the 'cv' argument to the GridSearchCV constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function for printing out the grid search results\n",
    "def print_results(grid_result):\n",
    "    print(f\"Best accuracy: {grid_result.best_score_:0.3f} using {grid_result.best_params_} \\n\")\n",
    "    print(\"Results for each combination of model paramters:\")\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    for mean, stdev, param in zip(means, stds, params):\n",
    "        print(f\"{mean:0.3f} \\u00B1 {stdev:0.3f}, {param}\")\n",
    "\n",
    "# Create a function for turning the grid search results into a list of results to be plotted\n",
    "def make_data_to_plot(grid_result, cv):\n",
    "    results_arr = []\n",
    "    for i in range(cv):\n",
    "        result = list(grid_result.cv_results_[f'split{i}_test_score'])\n",
    "        results_arr.append(result)\n",
    "    results_arr = np.asarray(results_arr)\n",
    "    results_arr = results_arr.T\n",
    "    data_to_plot = results_arr.tolist()\n",
    "    return data_to_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2) Batch Size and Number of Epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we look at tuning the batch size and number of epochs used when fitting the network.\n",
    "\n",
    "Batch size: the number of events shown to the network before the weights are updated\n",
    "\n",
    "Number of epochs: the number of times that the entire training dataset is shown to the network during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to create the model, required for KerasClassifier\n",
    "def model():\n",
    "    # Define Sequential model with 1 hidden layer containing 42 neurons \n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.Input(shape=(12,)))\n",
    "    model.add(layers.Dense(42, activation='relu'))\n",
    "    model.add(layers.Dense(2))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(optimizer='Adam',\n",
    "              loss=SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create model\n",
    "model = KerasClassifier(build_fn=model, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the grid search parameters\n",
    "batch_size = [16, 32, 128]\n",
    "epochs = [4, 8, 16, 32]\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "# Create the GridSearchCV using 5-fold cross validation\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=5, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed: 24.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.670 using {'batch_size': 32, 'epochs': 32} \n",
      "\n",
      "Results for each combination of model paramters:\n",
      "0.654 ± 0.018, {'batch_size': 16, 'epochs': 4}\n",
      "0.646 ± 0.017, {'batch_size': 16, 'epochs': 8}\n",
      "0.659 ± 0.015, {'batch_size': 16, 'epochs': 16}\n",
      "0.639 ± 0.021, {'batch_size': 16, 'epochs': 32}\n",
      "0.653 ± 0.022, {'batch_size': 32, 'epochs': 4}\n",
      "0.644 ± 0.009, {'batch_size': 32, 'epochs': 8}\n",
      "0.669 ± 0.009, {'batch_size': 32, 'epochs': 16}\n",
      "0.670 ± 0.010, {'batch_size': 32, 'epochs': 32}\n",
      "0.646 ± 0.026, {'batch_size': 128, 'epochs': 4}\n",
      "0.651 ± 0.019, {'batch_size': 128, 'epochs': 8}\n",
      "0.652 ± 0.022, {'batch_size': 128, 'epochs': 16}\n",
      "0.656 ± 0.010, {'batch_size': 128, 'epochs': 32}\n"
     ]
    }
   ],
   "source": [
    "# Run the model trainnig\n",
    "grid_result = grid.fit(data_train, labels_train, sample_weight=sw_train)\n",
    "\n",
    "# Summarise results\n",
    "print_results(grid_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default batch size of 32 performed marginally better in this test. \n",
    "A higher number of epochs shows some correlation with higher accuracy. \n",
    "\n",
    "The best accuracy was found by using {'batch_size': 32, 'epochs': 32}. \n",
    "In close second was the {'batch_size': 32, 'epochs': 16}.\n",
    "\n",
    "Going forward the paramters we will use batch_size=32 and epochs=16, as this will half the training time compared to 32 epochs for only a slight loss in accuracy. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3) Optimisation Algorithm\n",
    "\n",
    "Now we will investigate the effects of changing the optimisation algorithm used. \n",
    "\n",
    "Optimisation algorithm: The algorithm used to update network weights in iterative based training\n",
    "\n",
    "By default we have been using the Adam optimiser. The Adam optimisation algorithm is an extension to stochastic gradient descent. \n",
    "\n",
    "Here we will evaluate the suite of different optimisation algorithms available in Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a new model\n",
    "def model(optimizer='adam'):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.Input(shape=(12,)))\n",
    "    model.add(layers.Dense(42, activation='relu'))\n",
    "    model.add(layers.Dense(2))\n",
    "    \n",
    "    model.compile(optimizer=optimizer,\n",
    "              loss=SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=model, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the grid search parameters\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "param_grid = dict(optimizer=optimizer)\n",
    "\n",
    "# Create the GridSearchCV using 5-fold cross validation\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=2, cv=5, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  35 out of  35 | elapsed: 15.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.662 using {'optimizer': 'Adam'} \n",
      "\n",
      "Results for each combination of model paramters:\n",
      "0.616 ± 0.095, {'optimizer': 'SGD'}\n",
      "0.638 ± 0.011, {'optimizer': 'RMSprop'}\n",
      "0.622 ± 0.006, {'optimizer': 'Adagrad'}\n",
      "0.491 ± 0.028, {'optimizer': 'Adadelta'}\n",
      "0.662 ± 0.015, {'optimizer': 'Adam'}\n",
      "0.657 ± 0.014, {'optimizer': 'Adamax'}\n",
      "0.652 ± 0.013, {'optimizer': 'Nadam'}\n"
     ]
    }
   ],
   "source": [
    "# Run the model trainnig, this time using only 2/4 CPU cores so my PC remains useable\n",
    "grid_result = grid.fit(data_train, labels_train, sample_weight=sw_train, epochs=16, batch_size=32)\n",
    "\n",
    "# Summarise results\n",
    "print_results(grid_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results show that the 'Adam' optimiser is marginally better than the other tested optimisation algorithms."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
